{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6TAvZHNyMxCfVnZ1zkJ48",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starkjiang/TrAC-Generative-Models/blob/main/variational_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toy Example Using Maximum Likelihood Estimation and Variational Inference\n",
        "\n",
        "In this tutorial, we generate a simple synthetic dataset and use two methods for demo, including Maximum Likelihood Estimation (MLE) and Variational Inference (VI).\n",
        "\n",
        "The dataset generation follows a simple linear model:\n",
        "\n",
        "$y = 2x+0.5\\epsilon$, where $x\\sim \\mathcal{N}(0,1)$ and $\\epsilon\\sim\\mathcal{N}(0,1)$\n",
        "\n",
        "# MLE\n",
        "\n",
        "We use a simple one-layer linear neural network with MLE, where we assume a Gaussian likelihood.\n",
        "\n",
        "$y\\sim\\mathcal{N}(g_\\theta(x), \\sigma^2)$\n",
        "\n",
        "$\\hat{\\theta}_{MLE} = \\text{argmax}_\\theta\\prod_{i}^nP(y_i|\\theta)$\n",
        "\n",
        "# Variational Inference\n",
        "\n",
        "In VI, we accept the fact that we may not get the true posterior $p(y|x)\\propto p(x|y)p(y)$, but we try to approximate this distribution with another parameterized distribution, say $Q_\\theta(y)$. If we choose a factorized Gaussian distribution, $Q_\\theta(y)$ would become $Q_\\theta(\\mu, \\text{diag}(\\sigma^2))$. **Note that we are now working with an 1D case and that this factorization doesn't mean much right now.** We want the distribution to be conditioned on $x$. Therefore, we define a function $g_\\theta: x\\mapsto \\mu, \\sigma$. The function $g_\\theta$ will be a neural network to predict the variational parameters. The model can thus be described as:\n",
        "\n",
        "$p(y)\\sim\\mathcal{N}(0,1)$ (Unit Gaussian Prior)\n",
        "\n",
        "$Q(y|x) = \\mathcal{N}(g_\\theta(x)_\n",
        "\\mu,\\text{diag}(g_\\theta(x)_{\\sigma^2}))$\n",
        "\n",
        "# Optimization Problem\n",
        "\n",
        "Note: Above we have defined the posterior and the variational distribution in the variable $y|x$. We will generalize to a more often used notation, which is defined by a latent variable $Z$.\n",
        "\n",
        "Variational Inference is done by maximizing the Evidence Lower Bound (ELBO), which can be written as follows:\n",
        "\n",
        "$\\text{argmax}_Z = \\mathbb{E}_{Z\\sim Q}[\\text{log}p(D|Z)] - \\mathcal{D}_{KL}(Q(Z)||p(Z))$,\n",
        "\n",
        "where $p(Z)$ is the prior.\n",
        "\n",
        "The first term on the right hand side in the last equality is called likelihood, but in VI, it has a more generic name, \"recosntruction loss\". While the second term is called KL-divergence between the prior and variational distribution.\n",
        "\n",
        "Next, we are going to rewrite the loss function to make it more adaptive to optimization.\n",
        "\n",
        "We substitute the definition of the KL-divergence into the loss function such that\n",
        "\n",
        "$\\mathbb{E}_{Z\\sim Q}[\\text{log}p(D|Z)] + \\int Q(z)\\text{log}\\frac{p(Z)}{Q(Z)}dZ$\n",
        "\n",
        "The integral term can be rewritten as an expectation in the following:\n",
        "\n",
        "$\\mathbb{E}_{Z\\sim Q}[\\text{log}p(D|Z)] + \\mathbb{E}_{Z\\sim Q(Z)}\\text{log}[\\frac{p(Z)}{Q(Z)}] = \\mathbb{E}_{Z\\sim Q}[\\text{log}p(D|Z)] + \\mathbb{E}_{Z\\sim Q(Z)}[\\text{log}p(Z)-\\text{log}Q(Z)]$\n",
        "\n",
        "Deriving those expectations can be some tedious mathematics, or maybe not even possible. Luckily we can get estimates of the mean by taking samples from $Q(Z)$\n",
        "and average over those results.\n",
        "\n",
        "# Reparameterization Trick\n",
        "\n",
        "However, **sampling from $Q(Z)$ will make the whole pipeline non-deterministic such that the differentiability cannot be guaranteed in the backpropagation. We avoid this problem by reparameterizing the samples from the distribution.**\n",
        "\n",
        "Instead of sampling directly from the variational distribution\n",
        "\n",
        "$z\\sim Q(\\mu, \\sigma^2)$\n",
        "\n",
        "We sample from a unit gaussian and recreate samples from the variational distribution. Now the stochasticity of $\\epsilon$ is external and will not prevent the flow of gradients.\n",
        "\n",
        "$z=\\mu + \\sigma\\odot \\epsilon$, where $\\epsilon\\sim\\mathcal{N}(0,1)$.\n",
        "\n",
        "Since the prior and the variational distribution are all Gaussian, the KL divergence can be computed as\n",
        "\n",
        "$\\mathcal{D}_{KL}(Q(Z)|P(Z)) = \\text{log}\\frac{\\sigma_2}{\\sigma_1}+\\frac{\\sigma_1^2+(\\mu_1-\\mu_2)^2}{2\\sigma_2^2} - \\frac{1}{2}$\n",
        "\n",
        "If $p(Z)\\sim\\mathcal{N}(0,1)$, then the last equation becomes\n",
        "\n",
        "$\\mathcal{D}_{KL}(Q(Z)|\\mathcal{N}(0,1)) = \\text{log}\\frac{1}{\\sigma_1}+\\frac{\\sigma_1^2+(\\mu_1-0)^2}{2} - \\frac{1}{2} = \\frac{\\mu_1^2+\\sigma_1^2}{2}-\\text{log}\\sigma_1-\\frac{1}{2}$.\n",
        "\n",
        "In implementation, we typically regard the entire $\\text{log}\\sigma_1$ as the learnable parameter.\n"
      ],
      "metadata": {
        "id": "fckxh4pu5JHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define a simple linear model.\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "class BayesianLinearRegression(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(BayesianLinearRegression, self).__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        # Define prior distributions for weights and bias\n",
        "        self.weight_mu = nn.Parameter(torch.zeros(out_features, in_features))\n",
        "        self.weight_log_sigma = nn.Parameter(\n",
        "            torch.zeros(out_features, in_features)\n",
        "        )\n",
        "        self.bias_mu = nn.Parameter(torch.zeros(out_features))\n",
        "        self.bias_log_sigma = nn.Parameter(torch.zeros(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reparameterization trick for sampling weights and bias\n",
        "        weight_epsilon = torch.randn_like(self.weight_mu)\n",
        "        bias_epsilon = torch.randn_like(self.bias_mu)\n",
        "\n",
        "        weight = self.weight_mu + self.weight_log_sigma.exp() * weight_epsilon\n",
        "        bias = self.bias_mu + self.bias_log_sigma.exp() * bias_epsilon\n",
        "\n",
        "        return x @ weight.t() + bias\n",
        "\n",
        "    def elbo(self, x, y):\n",
        "        # TODO: Compute the negative ELBO loss\n",
        "        ########################## Your code is here!###########################\n",
        "        # 1. Calculate the prediction based on the forward function.\n",
        "        # 2. Calculate the log_likelihood for the ground truth and predictions.\n",
        "        # 3. Calculate the explicit KL divergence based on the formula in the\n",
        "        # text block.\n",
        "        # Note: the prior distribution follows standard Normal distribution\n",
        "        # N(0,1).\n",
        "        # 4. Return the elbo.\n",
        "        ########################################################################\n",
        "        return None\n",
        "\n",
        "# Generate some synthetic data\n",
        "x = torch.randn(100, 1)\n",
        "y = 2 * x + 1 + 0.5 * torch.randn(100, 1)\n",
        "\n",
        "# Maximum Likelihood Estimation (MLE)\n",
        "model_mle = LinearModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_mle.parameters(), lr=0.01)\n",
        "\n",
        "# Train the MLE model\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model_mle(x)\n",
        "    loss = criterion(y_pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Create model and optimizer\n",
        "model_vi = BayesianLinearRegression(1, 1)\n",
        "optimizer = optim.Adam(model_vi.parameters())\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    loss = model_vi.elbo(x, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Testing and plotting\n",
        "x_test = torch.linspace(-3, 3, 100).unsqueeze(1)\n",
        "y_pred_list = []\n",
        "for _ in range(100):\n",
        "    y_pred = model_vi(x_test)\n",
        "    y_pred_list.append(y_pred.detach())\n",
        "\n",
        "y_pred_mean = torch.mean(torch.stack(y_pred_list), dim=0)\n",
        "y_pred_std = torch.std(torch.stack(y_pred_list), dim=0)\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.plot(\n",
        "    x_test.numpy(),\n",
        "    model_mle(x_test).detach().numpy(),\n",
        "    color='g',\n",
        "    label='MLE'\n",
        ")\n",
        "plt.plot(x_test, y_pred_mean, color='red', label=\"VI\")\n",
        "plt.fill_between(\n",
        "    x_test.squeeze(),\n",
        "    y_pred_mean.squeeze() - 2 * y_pred_std.squeeze(),\n",
        "    y_pred_mean.squeeze() + 2 * y_pred_std.squeeze(),\n",
        "    alpha=0.2\n",
        ")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "OaIwaVrxBSiF",
        "outputId": "a7aeee53-69ac-4e5d-efdb-45144182675b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'backward'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ef2b4b5619d5>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_vi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'backward'"
          ]
        }
      ]
    }
  ]
}